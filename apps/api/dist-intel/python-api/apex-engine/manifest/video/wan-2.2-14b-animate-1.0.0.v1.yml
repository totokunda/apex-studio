api_version: apex/v1
kind: Model
metadata:
  id: wan-2-2-14b-animate
  model: wan
  name: Wan 2.2 14B Animate
  version: 1.0.0
  description: Wan 2.2 14B is a 14B parameter model for animate generation.
  tags:
  - wan
  - animate
  - 14b
  - '2.2'
  author: Apex AI
  license: Apache-2.0
  demo_path: models/wan-animate.mp4
  categories:
  - control
spec:
  engine: wan
  model_type: animate
  engine_type: torch
  denoise_type: base
  default_duration_secs: 5.0
  min_duration_secs: 1.0
  fps: 16
  compute_requirements:
    min_cuda_compute_capability: 7.5
    supported_compute_types:
    - cuda
    - cpu
    - metal
  attention_types:
  - sdpa
  - flash
  - flash3
  - sage
  - metal_flash
  - efficient_dot_product_attention
  loras:
  - source: Wan-AI/Wan2.2-Animate-14B/relighting_lora/adapter_model.safetensors
    scale: 1.0
    name: relighting_lora
    label: Relighting LoRA
    component: transformer
    verified: true
  - source: lightx2v/Wan2.1-Distill-Loras/wan2.1_i2v_lora_rank64_lightx2v_4step.safetensors
    scale: 1.0
    name: lightx2v_lora
    label: Lightx2v LoRA
    component: transformer
    verified: true
  components:
  - type: scheduler
    label: Scheduler
    default: UniPCMultistepScheduler
    scheduler_options:
    - name: UniPCMultistepScheduler
      label: UniPC Multistep Scheduler
      description: The UniPC Multistep Scheduler is used for WAN 2.2 14B Speech to
        Video.
      base: diffusers.UniPCMultistepScheduler
      config_path: Wan-AI/Wan2.2-Animate-14B-Diffusers/scheduler/scheduler_config.json
  - type: vae
    name: wan/vae
    label: Wan VAE
    base: wan
    model_path:
    - path: Wan-AI/Wan2.2-I2V-A14B-Diffusers/vae
      variant: default
      precision: fp16
      type: safetensors
      file_size: 507592616
      resource_requirements:
        min_vram_gb: 8
        recommended_vram_gb: 12
  - type: text_encoder
    label: WAN Text Encoder
    base: UMT5EncoderModel
    offloading_module: encoder
    model_path:
    - path: Wan-AI/Wan2.2-I2V-A14B-Diffusers/text_encoder
      variant: default
      precision: fp16
      type: safetensors
      file_size: 11361874539
      resource_requirements:
        min_vram_gb: 15
        recommended_vram_gb: 20
    - path: Kijai/WanVideo_comfy/umt5-xxl-enc-fp8_e4m3fn.safetensors
      variant: FP8
      precision: fp8
      type: safetensors
      file_size: 6731333792
      resource_requirements:
        min_vram_gb: 13
        recommended_vram_gb: 18
    config_path: Wan-AI/Wan2.1-I2V-14B-480P-Diffusers/text_encoder/config.json
  - type: transformer
    base: wan.animate
    label: Wan Transformer
    model_path:
    - path: Wan-AI/Wan2.2-Animate-14B-Diffusers/transformer
      variant: default
      precision: fp16
      type: safetensors
      file_size: 69099547207
      resource_requirements:
        min_vram_gb: 56
        recommended_vram_gb: 75
    - path: Kijai/WanVideo_comfy_fp8_scaled/Wan22Animate/Wan2_2-Animate-14B_fp8_scaled_e4m3fn_KJ_v2.safetensors
      variant: FP8
      precision: fp8
      type: safetensors
      file_size: 17317143060
      resource_requirements:
        min_vram_gb: 21
        recommended_vram_gb: 28
    - path: QuantStack/Wan2.2-Animate-14B-GGUF/Wan2.2-Animate-14B-Q8_0.gguf
      variant: GGUF_Q8_0
      precision: q8_0
      type: gguf
      file_size: 18719217472
      resource_requirements:
        min_vram_gb: 19
        recommended_vram_gb: 26
    - path: QuantStack/Wan2.2-Animate-14B-GGUF/Wan2.2-Animate-14B-Q6_K.gguf
      variant: GGUF_Q6_K
      precision: q6_k
      type: gguf
      file_size: 14605195072
      resource_requirements:
        min_vram_gb: 13
        recommended_vram_gb: 18
    - path: QuantStack/Wan2.2-Animate-14B-GGUF/Wan2.2-Animate-14B-Q5_K_M.gguf
      variant: GGUF_Q5_K_M
      precision: q5_k_m
      type: gguf
      file_size: 13003659072
      resource_requirements:
        min_vram_gb: 11
        recommended_vram_gb: 15
    - path: QuantStack/Wan2.2-Animate-14B-GGUF/Wan2.2-Animate-14B-Q5_K_S.gguf
      variant: GGUF_Q5_K_S
      precision: q5_k_s
      type: gguf
      file_size: 12349118272
      resource_requirements:
        min_vram_gb: 11
        recommended_vram_gb: 15
    - path: QuantStack/Wan2.2-Animate-14B-GGUF/Wan2.2-Animate-14B-Q5_0.gguf
      variant: GGUF_Q5_0
      precision: q5_0
      type: gguf
      file_size: 12526065472
      resource_requirements:
        min_vram_gb: 11
        recommended_vram_gb: 15
    - path: QuantStack/Wan2.2-Animate-14B-GGUF/Wan2.2-Animate-14B-Q4_K_M.gguf
      variant: GGUF_Q4_K_M
      precision: q4_k_m
      type: gguf
      file_size: 11496331072
      resource_requirements:
        min_vram_gb: 9
        recommended_vram_gb: 13
    - path: QuantStack/Wan2.2-Animate-14B-GGUF/Wan2.2-Animate-14B-Q4_K_S.gguf
      variant: GGUF_Q4_K_S
      precision: q4_k_s
      type: gguf
      file_size: 10592753472
      resource_requirements:
        min_vram_gb: 9
        recommended_vram_gb: 13
    - path: QuantStack/Wan2.2-Animate-14B-GGUF/Wan2.2-Animate-14B-Q4_0.gguf
      variant: GGUF_Q4_0
      precision: q4_0
      type: gguf
      file_size: 10402699072
      resource_requirements:
        min_vram_gb: 9
        recommended_vram_gb: 13
    - path: QuantStack/Wan2.2-Animate-14B-GGUF/Wan2.2-Animate-14B-Q3_K_M.gguf
      variant: GGUF_Q3_K_M
      precision: q3_k_m
      type: gguf
      file_size: 8630769472
      resource_requirements:
        min_vram_gb: 9
        recommended_vram_gb: 13
    - path: QuantStack/Wan2.2-Animate-14B-GGUF/Wan2.2-Animate-14B-Q3_K_S.gguf
      variant: GGUF_Q3_K_S
      precision: q3_k_s
      type: gguf
      file_size: 7969675072
      resource_requirements:
        min_vram_gb: 9
        recommended_vram_gb: 13
    - path: QuantStack/Wan2.2-Animate-14B-GGUF/Wan2.2-Animate-14B-Q2_K.gguf
      variant: GGUF_Q2_K
      precision: q2_k
      type: gguf
      file_size: 6457431872
      resource_requirements:
        min_vram_gb: 8
        recommended_vram_gb: 12
    config_path: Wan-AI/Wan2.2-Animate-14B-Diffusers/transformer/config.json
  - type: helper
    name: image_processor
    label: Image Processor
    base: CLIPImageProcessor
    module: transformers
    model_path:
    - path: Wan-AI/Wan2.2-Animate-14B-Diffusers/image_processor
      variant: default
      precision: fp16
      type: safetensors
      file_size: 5030848
      resource_requirements:
        min_vram_gb: 5
        recommended_vram_gb: 9
  - type: helper
    name: image_encoder
    label: Image Encoder
    base: CLIPVisionModel
    module: transformers
    model_path:
    - path: Wan-AI/Wan2.2-Animate-14B-Diffusers/image_encoder
      variant: default
      precision: fp16
      type: safetensors
      file_size: 1261596722
      resource_requirements:
        min_vram_gb: 5
        recommended_vram_gb: 9
  defaults:
    run:
      num_inference_steps: 4
      guidance_scale: 1.0
      return_latents: false
      text_encoder_kwargs:
        use_attention_mask: true
      attention_kwargs: {}
  ui:
    panels:
    - name: mode
      label: Mode
      collapsible: true
      default_open: true
      layout:
        flow: column
        rows:
        - - mode
    - name: image
      label: Image
      collapsible: true
      default_open: true
      layout:
        flow: column
        rows:
        - - image
    - name: videos
      label: Videos
      collapsible: true
      default_open: true
      layout:
        flow: column
        rows:
        - - pose_video
        - - face_video
    - name: replace_videos
      label: Replace Videos
      collapsible: true
      default_open: false
      layout:
        flow: column
        rows:
        - - background_video
        - - mask_video
    - name: prompting
      label: Prompting
      collapsible: true
      default_open: true
      layout:
        flow: column
        rows:
        - - prompt
    - name: advanced_prompting
      label: Advanced Prompting
      collapsible: true
      default_open: false
      layout:
        flow: column
        rows:
        - - negative_prompt
    - name: size
      label: Size
      collapsible: true
      default_open: false
      layout:
        flow: column
        rows:
        - - resolution
        - - aspect_ratio
        - - height
          - width
    - name: sampling
      label: Sampling
      collapsible: true
      default_open: false
      layout:
        flow: column
        rows:
        - - num_inference_steps
        - - guidance_scale
        - - seed
    - name: chunking_profile
      label: Chunking Profile
      collapsible: true
      default_open: false
      layout:
        flow: column
        rows:
        - - chunking_profile
        - - rope_on_cpu
    inputs:
    - id: mode
      label: Mode
      description: The mode to use for the generation.
      type: select
      panel: mode
      required: true
      default: animate
      options:
      - name: Animate
        value: animate
      - name: Replace
        value: replace
    - id: image
      label: Image
      description: The image to condition on.
      type: image
      panel: image
      required: true
      map_h: height
      map_w: width
    - id: pose_video
      label: Pose Video
      description: The pose video to condition on.
      preprocessor_ref: pose2d
      type: video+preprocessor
      panel: videos
      required: true
    - id: face_video
      label: Face Video
      description: The face video to condition on.
      preprocessor_ref: face2d
      type: video+preprocessor
      panel: videos
      required: true
    - id: background_video
      label: Background Video
      description: The background video to condition on.
      type: video
      panel: videos
      required: false
    - id: mask_video
      label: Mask Video
      description: The mask video to condition on.
      type: video+mask
      panel: videos
      required: false
    - id: prompt
      label: Prompt
      description: Describe the image you want to generate.
      placeholder: A beautiful landscape at golden hour.
      type: text
      panel: prompting
      required: true
    - id: negative_prompt
      label: Negative Prompt
      description: Describe what to avoid in the generation.
      placeholder: blurry, low quality, distorted, artifacts
      type: text
      panel: advanced_prompting
      required: false
    - id: resolution
      label: Resolution
      description: Select the resolution of the output image
      panel: size
      type: select
      default: 480
      options:
      - name: SD
        value: 480
      - name: HD
        value: 720
      - name: Custom
        value: custom
    - id: num_inference_steps
      label: Inference Steps
      description: Number of denoising steps
      type: number+slider
      value_type: integer
      panel: sampling
      default: 4
      min: 1
      max: 100
      step: 1
    - id: aspect_ratio
      label: Aspect Ratio
      description: Select the aspect ratio of the output image
      panel: size
      type: select
      default: '9:16'
      options:
      - name: Wide
        value: '16:9'
        ratio_w: 16
        ratio_h: 9
      - name: Vertical
        value: '9:16'
        ratio_w: 9
        ratio_h: 16
      - name: Classic
        value: '4:3'
        ratio_w: 4
        ratio_h: 3
      - name: Square
        value: '1:1'
        ratio_w: 1
        ratio_h: 1
      - name: Custom
        value: custom
    - id: height
      label: Height
      description: Explicit height override
      type: number
      value_type: integer
      panel: size
      default: 480
      min: 256
      max: 8192
      step: 16
    - id: width
      label: Width
      description: Explicit width override
      type: number
      value_type: integer
      panel: size
      default: 832
      min: 256
      max: 8192
      step: 16
    - id: seed
      label: Seed
      description: Random seed for reproducibility
      type: random
      default: -1
      min: 0
      max: 4294967295
      value_type: integer
      panel: sampling
      required: false
    - id: guidance_scale
      label: Guidance Scale
      type: number+slider
      value_type: float
      panel: sampling
      required: false
      default: 1.0
      min: 1.0
      max: 15.0
      step: 0.5
    - id: chunking_profile
      label: Chunking Profile
      description: Spliting tensors into smaller chunks to reduce memory usage.
      type: select
      panel: chunking_profile
      default: light
      options:
      - name: None
        value: none
      - name: Light
        value: light
      - name: Balanced
        value: balanced
      - name: Aggressive
        value: aggressive
    - id: rope_on_cpu
      label: Rope Frequency on CPU
      description: Keep RoPE frequency tables on CPU to save VRAM; small slices are moved to GPU only when needed.
      type: boolean
      panel: chunking_profile
      default: false
      required: false
