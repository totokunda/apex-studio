api_version: apex/v1
kind: Model
metadata:
  id: longcat-13b-vc
  model: longcat
  name: LongCat 13B VC
  version: 1.0.0
  description: LongCat 13B is a 13B parameter model for VC generation.
  tags:
  - longcat
  - vc
  - 13b
  author: Apex AI
  license: Apache-2.0
  demo_path: https://i.ytimg.com/vi/baS0ZIkt3gM/maxresdefault.jpg
spec:
  engine: longcat
  model_type: vc
  engine_type: torch
  attention_types:
  - flash
  - flash3
  fps: 15
  components:
  - type: scheduler
    label: Scheduler
    default: FlowMatchEulerDiscreteScheduler
    scheduler_options:
    - name: FlowMatchEulerDiscreteScheduler
      label: FlowMatch Euler Discrete Scheduler
      description: The UniPC Multistep Scheduler is used for LongCat 13B T2V.
      base: diffusers.FlowMatchEulerDiscreteScheduler
      config_path: meituan-longcat/LongCat-Video/scheduler/scheduler_config.json
  - type: vae
    name: wan/vae
    label: Wan VAE
    base: wan
    model_path:
    - path: Wan-AI/Wan2.1-I2V-14B-480P-Diffusers/vae
      variant: default
      precision: fp16
      type: safetensors
      file_size: 507592616
    config_path: https://huggingface.co/Wan-AI/Wan2.1-I2V-14B-480P-Diffusers/resolve/main/vae/config.json
  - type: text_encoder
    name: wan/text_encoder
    base: UMT5EncoderModel
    label: UMT5 Text Encoder
    model_path:
    - path: Wan-AI/Wan2.1-I2V-14B-480P-Diffusers/text_encoder
      variant: default
      precision: fp16
      type: safetensors
      file_size: 22723695074
    config_path: https://huggingface.co/Wan-AI/Wan2.1-I2V-14B-480P-Diffusers/resolve/main/text_encoder/config.json
  - type: transformer
    base: longcat.base
    label: LongCat Transformer
    model_path:
    - path: meituan-longcat/LongCat-Video/dit
      variant: default
      precision: fp16
      type: safetensors
    config_path: meituan-longcat/LongCat-Video/dit/config.json
  loras:
  - source: meituan-longcat/LongCat-Video/lora/cfg_step_lora.safetensors
    scale: 1.0
    verified: true
    name: cfg_step_lora
    label: LongCat 13B CFG Step LoRA
  defaults:
    run:
      num_inference_steps: 30
      guidance_scale: 5.0
      return_latents: false
      timesteps_as_indices: true
      expand_timesteps: false
      text_encoder_kwargs: {}
      attention_kwargs: {}
  