api_version: apex/v1
kind: Model
type: video
metadata:
  id: wan-2-2-14b-animate
  model: wan
  name: Wan 2.2 14B Animate
  version: 0.1.2
  description: Wan 2.2 14B is a 14B parameter model for animate generation.
  tags:
  - wan
  - animate
  - 14b
  - '2.2'
  author: Apex AI
  license: Apache-2.0
  demo_path: models/wan-animate.mp4
  categories:
  - control
spec:
  engine: wan
  model_type: animate
  engine_type: torch
  denoise_type: base
  default_duration_secs: 5.0
  fps: 16
  compute_requirements:
    min_cuda_compute_capability: 7.5
    supported_compute_types:
    - cuda
    - cpu
    - metal
  attention_types:
  - sdpa
  - flash
  - flash3
  - sage
  - metal_flash
  - efficient_dot_product_attention
  loras:
  - source: Wan-AI/Wan2.2-Animate-14B/relighting_lora/adapter_model.safetensors
    scale: 1.0
    name: relighting_lora
    label: Relighting LoRA
    component: transformer
    verified: true
  - source: lightx2v/Wan2.1-Distill-Loras/wan2.1_i2v_lora_rank64_lightx2v_4step.safetensors
    scale: 1.0
    name: lightx2v_lora
    label: Lightx2v LoRA
    component: transformer
    verified: true
  components:
  - type: scheduler
    label: Scheduler
    default: UniPCMultistepSchedulerBH2
    scheduler_manifest: schedulers/flow_matching.yml
    scheduler_config_defaults:
      num_train_timesteps: 1000
      shift: 5.0
      sigma_max: 1.0
      sigma_min: 0.002994011976047904
  - type: vae
    label: WAN VAE
    name: vae
    base: wan
    config_path: totoku/apex-models/Wan2.2-I2V/vae/config.json
    model_path:
    - path: totoku/apex-models/Wan2.2-I2V/vae/vae-bf16.safetensors
      variant: default
      precision: bf16
      type: safetensors
  - type: text_encoder
    label: WAN Text Encoder
    base: UMT5EncoderModel
    offloading_module: encoder
    config_path: totoku/apex-models/Wan2.1-T2V/text_encoder/config.json
    model_path:
    - path: totoku/apex-models/Wan2.1-T2V/text_encoder/text_encoder-bf16.safetensors
      variant: default
      precision: bf16
      type: safetensors
    - path: totoku/apex-models/Wan2.1-T2V/text_encoder/text_encoder-fp8_e4m3fn.safetensors
      variant: FP8_E4M3FN
      precision: fp8_e4m3fn
      type: safetensors
    - path: totoku/apex-models/Wan2.1-T2V/text_encoder/text_encoder-q8_0.gguf
      variant: GGUF_Q8_0
      precision: q8_0
      type: gguf
    tokenizer_class: T5Tokenizer
    tokenizer_name: totoku/apex-models
    tokenizer_kwargs:
      subfolder: Wan2.1-T2V/tokenizer
  - type: transformer
    base: wan.animate
    label: Wan Transformer
    config_path: totoku/apex-models/Wan2.2-Animate/transformer/config.json
    model_path:
    - path: totoku/apex-models/Wan2.2-Animate/transformer/transformer-bf16.safetensors
      variant: default
      precision: bf16
      type: safetensors
    - path: totoku/apex-models/Wan2.2-Animate/transformer/transformer-fp8_e4m3fn.safetensors
      variant: FP8_E4M3FN
      precision: fp8_e4m3fn
      type: safetensors
    - path: totoku/apex-models/Wan2.2-Animate/transformer/transformer-q8_0.gguf
      variant: GGUF_Q8_0
      precision: q8_0
      type: gguf
    - path: totoku/apex-models/Wan2.2-Animate/transformer/transformer-q6_k.gguf
      variant: GGUF_Q6_K
      precision: q6_k
      type: gguf
    - path: totoku/apex-models/Wan2.2-Animate/transformer/transformer-q4_k_m.gguf
      variant: GGUF_Q4_K_M
      precision: q4_k_m
      type: gguf
  - type: helper
    name: image_processor
    label: Image Processor
    base: CLIPImageProcessor
    module: transformers
    model_path:
    - path: totoku/apex-models/Wan2.1-I2V-480P/image_processor
      variant: default
      precision: fp16
      type: safetensors
  - type: helper
    name: image_encoder
    label: Image Encoder
    base: CLIPVisionModel
    module: transformers
    model_path:
    - path: totoku/apex-models/Wan2.1-I2V-480P/image_encoder
      variant: default
      precision: fp16
      type: safetensors
  defaults:
    run:
      num_inference_steps: 4
      guidance_scale: 1.0
      return_latents: false
      text_encoder_kwargs:
        use_attention_mask: true
      attention_kwargs: {}
  ui:
    panels:
    - name: mode
      label: Mode
      collapsible: true
      default_open: true
      layout:
        flow: column
        rows:
        - - mode
    - name: image
      label: Image
      collapsible: true
      default_open: true
      layout:
        flow: column
        rows:
        - - image
    - name: videos
      label: Videos
      collapsible: true
      default_open: true
      layout:
        flow: column
        rows:
        - - pose_video
        - - face_video
    - name: replace_videos
      label: Replace Videos
      collapsible: true
      default_open: false
      layout:
        flow: column
        rows:
        - - background_video
        - - mask_video
    - name: prompting
      label: Prompting
      collapsible: true
      default_open: true
      layout:
        flow: column
        rows:
        - - prompt
    - name: advanced_prompting
      label: Advanced Prompting
      collapsible: true
      default_open: false
      layout:
        flow: column
        rows:
        - - negative_prompt
    - name: size
      label: Size
      collapsible: true
      default_open: false
      layout:
        flow: column
        rows:
        - - resolution
        - - aspect_ratio
        - - height
          - width
    - name: sampling
      label: Sampling
      collapsible: true
      default_open: false
      layout:
        flow: column
        rows:
        - - num_inference_steps
        - - guidance_scale
        - - seed
    - name: chunking_profile
      label: Chunking Profile
      collapsible: true
      default_open: false
      layout:
        flow: column
        rows:
        - - chunking_profile
        - - rope_on_cpu
    inputs:
    - id: mode
      label: Mode
      description: The mode to use for the generation.
      type: select
      panel: mode
      required: true
      default: animate
      options:
      - name: Animate
        value: animate
      - name: Replace
        value: replace
    - id: image
      label: Image
      description: The image to condition on.
      type: image
      panel: image
      required: true
      map_h: height
      map_w: width
    - id: pose_video
      label: Pose Video
      description: The pose video to condition on.
      preprocessor_ref: pose2d
      type: video+preprocessor
      panel: videos
      required: true
    - id: face_video
      label: Face Video
      description: The face video to condition on.
      preprocessor_ref: face2d
      type: video+preprocessor
      panel: videos
      required: true
    - id: background_video
      label: Background Video
      description: The background video to condition on.
      type: video
      panel: videos
      required: false
    - id: mask_video
      label: Mask Video
      description: The mask video to condition on.
      type: video+mask
      panel: videos
      required: false
    - id: prompt
      label: Prompt
      description: Describe the image you want to generate.
      placeholder: A beautiful landscape at golden hour.
      type: text
      panel: prompting
      required: true
    - id: negative_prompt
      label: Negative Prompt
      description: Describe what to avoid in the generation.
      placeholder: blurry, low quality, distorted, artifacts
      type: text
      panel: advanced_prompting
      required: false
    - id: resolution
      label: Resolution
      description: Select the resolution of the output image
      panel: size
      type: select
      default: 480
      options:
      - name: SD
        value: 480
      - name: HD
        value: 720
      - name: Custom
        value: custom
    - id: num_inference_steps
      label: Inference Steps
      description: Number of denoising steps
      type: number+slider
      value_type: integer
      panel: sampling
      default: 4
      min: 1
      max: 100
      step: 1
    - id: aspect_ratio
      label: Aspect Ratio
      description: Select the aspect ratio of the output image
      panel: size
      type: select
      default: '9:16'
      options:
      - name: Wide
        value: '16:9'
        ratio_w: 16
        ratio_h: 9
      - name: Vertical
        value: '9:16'
        ratio_w: 9
        ratio_h: 16
      - name: Classic
        value: '4:3'
        ratio_w: 4
        ratio_h: 3
      - name: Square
        value: '1:1'
        ratio_w: 1
        ratio_h: 1
      - name: Custom
        value: custom
    - id: height
      label: Height
      description: Explicit height override
      type: number
      value_type: integer
      panel: size
      default: 480
      min: 256
      max: 8192
      step: 16
    - id: width
      label: Width
      description: Explicit width override
      type: number
      value_type: integer
      panel: size
      default: 832
      min: 256
      max: 8192
      step: 16
    - id: seed
      label: Seed
      description: Random seed for reproducibility
      type: random
      default: -1
      min: 0
      max: 4294967295
      value_type: integer
      panel: sampling
      required: false
    - id: guidance_scale
      label: Guidance Scale
      type: number+slider
      value_type: float
      panel: sampling
      required: false
      default: 1.0
      min: 1.0
      max: 15.0
      step: 0.5
    - id: chunking_profile
      label: Chunking Profile
      description: Spliting tensors into smaller chunks to reduce memory usage.
      type: select
      panel: chunking_profile
      default: light
      options:
      - name: None
        value: none
      - name: Light
        value: light
      - name: Balanced
        value: balanced
      - name: Aggressive
        value: aggressive
    - id: rope_on_cpu
      label: Rope Frequency on CPU
      description: Keep RoPE frequency tables on CPU to save VRAM; small slices are moved to GPU only when needed.
      type: boolean
      panel: chunking_profile
      default: false
      required: false
