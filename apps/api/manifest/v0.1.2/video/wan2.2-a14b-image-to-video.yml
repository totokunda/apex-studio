api_version: apex/v1
kind: Model
type: video
metadata:
  id: wan-2-2-a14b-image-to-video
  model: wan
  name: Wan 2.2 A14B Image to Video
  version: 0.1.2
  description: Wan 2.2 A14B is a 14B parameter model for image-to-video generation.
  tags:
  - wan
  - i2v
  - 14b
  - '2.2'
  author: Wan-AI
  license: Apache-2.0
  demo_path: models/wan-2.2-i2v-14b.mp4
  categories:
  - image-to-video
spec:
  engine: wan
  model_type: i2v
  engine_type: torch
  denoise_type: moe
  fps: 16
  default_duration_secs: 5.0
  compute_requirements:
    min_cuda_compute_capability: 7.5
    supported_compute_types:
    - cuda
    - cpu
    - metal
  attention_types:
  - sdpa
  - flash
  - flash3
  - sage
  - metal_flash
  - efficient_dot_product_attention
  loras:
  - source: lightx2v/Wan2.2-Distill-Loras/wan2.2_i2v_A14b_high_noise_lora_rank64_lightx2v_4step_1022.safetensors
    scale: 1.0
    verified: true
    name: high_noise_lightning_lora
    label: High Noise Lightning LoRA
    component: high_noise_transformer
  - source: lightx2v/Wan2.2-Distill-Loras/wan2.2_i2v_A14b_low_noise_lora_rank64_lightx2v_4step_1022.safetensors
    scale: 1.0
    verified: true
    name: low_noise_lightning_lora
    label: Low Noise Lightning LoRA
    component: low_noise_transformer
  components:
  - type: scheduler
    label: Scheduler
    default: UniPCMultistepScheduler
    scheduler_options:
    - name: UniPCMultistepScheduler
      label: UniPC Multistep Scheduler
      description: The UniPC Multistep Scheduler is used for WAN 2.2 A14B I2V.
      base: diffusers.UniPCMultistepScheduler
      config_path: Wan-AI/Wan2.2-I2V-A14B-Diffusers/scheduler/scheduler_config.json
  - type: vae
    label: WAN VAE
    name: vae
    base: wan
    config_path: totoku/apex-models/Wan2.2-I2V/vae/config.json
    model_path:
    - path: totoku/apex-models/Wan2.2-I2V/vae/vae-bf16.safetensors
      variant: default
      precision: bf16
      type: safetensors
  - type: text_encoder
    label: WAN Text Encoder
    base: UMT5EncoderModel
    offloading_module: encoder
    config_path: totoku/apex-models/Wan2.1-T2V/text_encoder/config.json
    model_path:
    - path: totoku/apex-models/Wan2.1-T2V/text_encoder/text_encoder-bf16.safetensors
      variant: default
      precision: bf16
      type: safetensors
    - path: totoku/apex-models/Wan2.1-T2V/text_encoder/text_encoder-fp8_e4m3fn.safetensors
      variant: FP8_E4M3FN
      precision: fp8_e4m3fn
      type: safetensors
    - path: totoku/apex-models/Wan2.1-T2V/text_encoder/text_encoder-q8_0.gguf
      variant: GGUF_Q8_0
      precision: q8_0
      type: gguf
    tokenizer_class: T5Tokenizer
    tokenizer_name: totoku/apex-models
    tokenizer_kwargs:
      subfolder: Wan2.1-T2V/tokenizer
  - type: transformer
    label: High Noise Transformer
    name: high_noise_transformer
    base: wan.base
    config_path: totoku/apex-models/Wan2.2-SmoothMix-I2V/high_noise_transformer/config.json
    model_path:
    - path: totoku/apex-models/Wan2.2-SmoothMix-I2V/high_noise_transformer/transformer-bf16.safetensors
      variant: default
      precision: bf16
      type: safetensors
    - path: totoku/apex-models/Wan2.2-SmoothMix-I2V/high_noise_transformer/transformer-fp8_e4m3fn.safetensors
      variant: FP8_E4M3FN
      precision: fp8_e4m3fn
      type: safetensors
    - path: totoku/apex-models/Wan2.2-SmoothMix-I2V/high_noise_transformer/transformer-q8_0.gguf
      variant: GGUF_Q8_0
      precision: q8_0
      type: gguf
    - path: totoku/apex-models/Wan2.2-SmoothMix-I2V/high_noise_transformer/transformer-q6_k.gguf
      variant: GGUF_Q6_K
      precision: q6_k
      type: gguf
    - path: totoku/apex-models/Wan2.2-SmoothMix-I2V/high_noise_transformer/transformer-q4_k_m.gguf
      variant: GGUF_Q4_K_M
      precision: q4_k_m
      type: gguf
  - type: transformer
    label: Low Noise Transformer
    name: low_noise_transformer
    base: wan.base
    config_path: totoku/apex-models/Wan2.2-SmoothMix-I2V/low_noise_transformer/config.json
    model_path:
    - path: totoku/apex-models/Wan2.2-SmoothMix-I2V/low_noise_transformer/transformer-bf16.safetensors
      variant: default
      precision: bf16
      type: safetensors
    - path: totoku/apex-models/Wan2.2-SmoothMix-I2V/low_noise_transformer/transformer-fp8_e4m3fn.safetensors
      variant: FP8_E4M3FN
      precision: fp8_e4m3fn
      type: safetensors
    - path: totoku/apex-models/Wan2.2-SmoothMix-I2V/low_noise_transformer/transformer-q8_0.gguf
      variant: GGUF_Q8_0
      precision: q8_0
      type: gguf
    - path: totoku/apex-models/Wan2.2-SmoothMix-I2V/low_noise_transformer/transformer-q6_k.gguf
      variant: GGUF_Q6_K
      precision: q6_k
      type: gguf
    - path: totoku/apex-models/Wan2.2-SmoothMix-I2V/low_noise_transformer/transformer-q4_k_m.gguf
      variant: GGUF_Q4_K_M
      precision: q4_k_m
      type: gguf
  defaults:
    run:
      num_inference_steps: 4
      guidance_scale: 5.0
      return_latents: false
      timesteps_as_indices: true
      boundary_ratio: 0.875
      expand_timesteps: false
      text_encoder_kwargs: {}
      attention_kwargs: {}
  ui:
    panels:
    - name: input
      label: Input
      collapsible: true
      default_open: true
      layout:
        flow: column
        rows:
        - - image
    - name: prompting
      label: Prompting
      collapsible: true
      default_open: true
      layout:
        flow: column
        rows:
        - - prompt
    - name: advanced_prompting
      label: Advanced Prompting
      collapsible: true
      default_open: false
      layout:
        flow: column
        rows:
        - - negative_prompt
    - name: size
      label: Size
      collapsible: true
      default_open: false
      layout:
        flow: column
        rows:
        - - resolution
        - - aspect_ratio
        - - height
          - width
    - name: sampling
      label: Sampling
      collapsible: true
      default_open: false
      layout:
        flow: column
        rows:
        - - num_inference_steps
        - - high_noise_guidance_scale
        - - low_noise_guidance_scale
        - - seed
        - - boundary_ratio
    - name: chunking_profile
      label: Chunking Profile
      collapsible: true
      default_open: false
      layout:
        flow: column
        rows:
        - - chunking_profile
        - - rope_on_cpu
    inputs:
    - id: image
      label: Image
      description: The input image to generate a video from.
      type: image
      panel: input
      required: true
      map_h: height
      map_w: width
      scale_by: resolution
    - id: prompt
      label: Prompt
      description: Describe the video you want to generate.
      placeholder: A beautiful landscape at golden hour.
      type: text
      panel: prompting
      required: true
    - id: negative_prompt
      label: Negative Prompt
      description: Describe what to avoid in the generation.
      placeholder: blurry, low quality, distorted, artifacts
      type: text
      panel: advanced_prompting
      required: false
      default: lowres, text, error, cropped, worst quality, low quality, jpeg artifacts,
        ugly, duplicate, morbid, mutilated, out of frame, extra fingers, mutated hands,
        poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated,
        bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross
        proportions, malformed limbs, missing arms, missing legs, extra arms, extra
        legs, fused fingers, too many fingers, long neck, username, watermark, signature
    - id: resolution
      label: Resolution
      description: Select the resolution of the output video
      panel: size
      type: select
      default: 720
      options:
      - name: HD
        value: 720
      - name: SD
        value: 480
      - name: Custom
        value: custom
    - id: aspect_ratio
      label: Aspect Ratio
      description: Select the aspect ratio of the output video
      panel: size
      type: select
      default: '1:1'
      options:
      - name: Square
        value: '1:1'
        ratio_w: 1
        ratio_h: 1
      - name: Wide
        value: '16:9'
        ratio_w: 16
        ratio_h: 9
      - name: Vertical
        value: '9:16'
        ratio_w: 9
        ratio_h: 16
      - name: Classic
        value: '4:3'
        ratio_w: 4
        ratio_h: 3
      - name: Custom
        value: custom
    - id: num_inference_steps
      label: Inference Steps
      description: Number of denoising steps
      type: number+slider
      value_type: integer
      panel: sampling
      default: 4
      min: 1
      max: 100
      step: 1
    - id: height
      label: Height
      description: Explicit height override
      type: number
      value_type: integer
      panel: size
      default: 480
      min: 256
      max: 8192
      step: 16
    - id: width
      label: Width
      description: Explicit width override
      type: number
      value_type: integer
      panel: size
      default: 832
      min: 256
      max: 8192
      step: 16
    - id: seed
      label: Seed
      description: Random seed for reproducibility
      type: random
      default: -1
      min: 0
      max: 4294967295
      value_type: integer
      panel: sampling
      required: false
    - id: high_noise_guidance_scale
      label: High Noise Guidance Scale
      type: number
      value_type: float
      panel: sampling
      required: false
      default: 1.0
      min: 1.0
      max: 15.0
      step: 0.1
    - id: low_noise_guidance_scale
      label: Low Noise Guidance Scale
      type: number
      value_type: float
      panel: sampling
      required: false
      default: 1.0
      min: 1.0
      max: 15.0
      step: 0.1
    - id: boundary_ratio
      label: Boundary Ratio
      description: The ratio of the boundary of the image
      type: number+slider
      value_type: float
      panel: sampling
      required: false
      default: 0.875
      min: 0.0
      max: 1.0
      step: 0.01
    - id: chunking_profile
      label: Chunking Profile
      description: Spliting tensors into smaller chunks to reduce memory usage.
      type: select
      panel: chunking_profile
      default: light
      options:
      - name: None
        value: none
      - name: Light
        value: light
      - name: Balanced
        value: balanced
      - name: Aggressive
        value: aggressive
    - id: rope_on_cpu
      label: Rope Frequency on CPU
      description: Keep RoPE frequency tables on CPU to save VRAM; small slices are
        moved to GPU only when needed.
      type: boolean
      panel: chunking_profile
      default: false
      required: false
