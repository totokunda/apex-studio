import torch

from src.engine.ltx22.shared.protocols import DiffusionStepProtocol
from src.engine.ltx22.shared.utils import to_velocity


class EulerDiffusionStep(DiffusionStepProtocol):
    """
    First-order Euler method for diffusion sampling.
    Takes a single step from the current noise level (sigma) to the next by
    computing velocity from the denoised prediction and applying: sample + velocity * dt.
    """

    def step(
        self, sample: torch.Tensor, denoised_sample: torch.Tensor, sigmas: torch.Tensor, step_index: int
    ) -> torch.Tensor:
        sigma = sigmas[step_index]
        sigma_next = sigmas[step_index + 1]
        dt = sigma_next - sigma
        velocity = to_velocity(sample, sigma, denoised_sample)

        return (sample.to(torch.float32) + velocity.to(torch.float32) * dt).to(sample.dtype)


class SchedulerDiffusionStep(DiffusionStepProtocol):
    """
    Adapter that wraps a loaded scheduler (from ``load_component_by_type('scheduler')``)
    to conform to the :class:`DiffusionStepProtocol` used by LTX-2 denoising loops.

    The LTX-2 transformer outputs denoised (x0) predictions.  This adapter
    converts them to flow / velocity predictions
    (``v = (sample - x0) / sigma``) before delegating to the scheduler's
    ``step()`` method, enabling the use of any flow-matching scheduler
    (Euler, Heun, DPM++, UniPC, etc.).
    """

    def __init__(self, scheduler):
        self.scheduler = scheduler
        # Reset the scheduler's step index for a fresh denoising run.
        if hasattr(scheduler, "_step_index"):
            scheduler._step_index = None

    def step(
        self,
        sample: torch.Tensor,
        denoised_sample: torch.Tensor,
        sigmas: torch.Tensor,
        step_index: int,
    ) -> torch.Tensor:
        sigma = sigmas[step_index]
        # Convert x0 prediction → flow /  velocity: v = (sample − x0) / σ
        velocity = to_velocity(sample, sigma, denoised_sample)

        timestep = self.scheduler.timesteps[step_index]
        result = self.scheduler.step(
            velocity, timestep, sample, return_dict=False
        )
        return result[0].to(sample.dtype)


def configure_scheduler_sigmas(
    scheduler, sigmas: torch.Tensor
) -> None:
    """
    Configure a scheduler's internal state to use specific sigma values.

    This is useful for distilled models whose sigma schedules are fixed
    constants rather than generated by the scheduler.  After calling this
    helper the scheduler's ``step()`` method will operate on the provided
    sigma schedule.
    """
    sigmas = sigmas.to(dtype=torch.float32)
    scheduler.sigmas = sigmas

    num_train_timesteps = getattr(
        getattr(scheduler, "config", None),
        "num_train_timesteps",
        getattr(scheduler, "num_train_timesteps", 1000),
    )
    scheduler.timesteps = (sigmas[:-1] * num_train_timesteps).to(
        dtype=torch.float32
    )
    scheduler.num_inference_steps = len(sigmas) - 1

    if hasattr(scheduler, "_step_index"):
        scheduler._step_index = None
